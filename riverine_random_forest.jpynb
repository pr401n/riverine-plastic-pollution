# %% [markdown]
"""
# River Plastic Pollution Classifier
**Professional Machine Learning Pipeline**

This Colab notebook implements a complete workflow for classifying rivers based on their plastic pollution contribution using Random Forest.
"""
# %%
# @title Data Loading & Setup
from google.colab import drive
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           confusion_matrix, ConfusionMatrixDisplay, 
                           classification_report, roc_curve, roc_auc_score)

# Constants
THRESHOLD = 6008  # Metric tons/year threshold for classification
RANDOM_STATE = 42  # For reproducibility
TEST_SIZE = 0.2    # Train-test split ratio

# Mount Google Drive
drive.mount('/content/drive')

# %%
# @title Data Cleaning & Preparation
def load_and_clean_data(filepath):
    """Load and preprocess river plastic pollution data."""
    df = pd.read_csv(filepath)
    
    # Convert European number formats (28'486 → 28486)
    num_cols = df.select_dtypes(include=['object']).columns
    for col in num_cols:
        if df[col].astype(str).str.contains(r"\d+'\d+").any():
            df[col] = df[col].astype(str).str.replace("'", "").astype(float)
    
    # Convert percentages
    pct_cols = [col for col in df.columns if '%' in col or '[%]' in col]
    for col in pct_cols:
        df[col] = df[col].astype(str).str.replace('%', '').astype(float) / 100
    
    return df.dropna(axis=1, how='all')

# Load data
data = load_and_clean_data('/content/drive/MyDrive/data/global_riverine_plastic_emissions_into_ocean.csv')
data.head()

# %%
# @title Feature Engineering
# Create target variable
data['plastic_contribution'] = (data['M[E] (metric tons year -1)'] <= THRESHOLD).astype(int)

# Base features
features = [
    'Area [km2]', 
    'Coast length [km]', 
    'Rainfall [mm year -1]',
    'MPW (metric tons year -1)', 
    'P[E] [%]', 
    'Factor (L/A) *P [-]'
]

# Add engineered features
data['coast_to_area_ratio'] = data['Coast length [km]'] / data['Area [km2]'].replace(0, 1e-6)
data['rainfall_per_km2'] = data['Rainfall [mm year -1]'] / data['Area [km2]'].replace(0, 1e-6)
features += ['coast_to_area_ratio', 'rainfall_per_km2']

X = data[features]
y = data['plastic_contribution']

# %%
# @title Exploratory Data Analysis
# Class distribution
plt.figure(figsize=(8, 5))
counts = y.value_counts()
bars = plt.bar(['Low (≤6008 tons)', 'High (>6008 tons)'], counts, 
               color=['#1f77b4', '#ff7f0e'])

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:,}',
            ha='center', va='bottom')

plt.title('River Plastic Contribution Distribution', pad=20)
plt.ylabel('Number of Rivers')
sns.despine()
plt.show()

# %%
# @title Data Preprocessing
# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
)

# Feature scaling
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# %%
# @title Model Training
model = RandomForestClassifier(
    n_estimators=500,
    max_depth=10,
    min_samples_leaf=5,
    class_weight='balanced',
    random_state=RANDOM_STATE,
    n_jobs=-1
)
model.fit(X_train_scaled, y_train)

# %%
# @title Model Evaluation
# Classification report
y_pred = model.predict(X_test_scaled)
print("=== Classification Report ===")
print(classification_report(y_test, y_pred))

# Confusion matrix
plt.figure(figsize=(6, 6))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix", pad=20)
plt.show()

# %%
# @title Feature Importance Analysis
importances = model.feature_importances_
importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\
                 .sort_values('Importance', ascending=True)

plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='#2ca02c')
plt.title('Feature Importance for Plastic Contribution Prediction', pad=20)
plt.xlabel('Relative Importance Score')
plt.grid(axis='x', alpha=0.3)
sns.despine()
plt.show()

# %%
# @title ROC Curve Analysis
y_probs = model.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
auc_score = roc_auc_score(y_test, y_probs)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='#9467bd', lw=2, 
         label=f'ROC Curve (AUC = {auc_score:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic', pad=20)
plt.legend(loc="lower right")
plt.grid(alpha=0.3)
plt.show()

# %%
# @title Final Summary
print("\n=== MODEL PERFORMANCE SUMMARY ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print(f"Precision: {precision_score(y_test, y_pred):.2f}")
print(f"Recall: {recall_score(y_test, y_pred):.2f}")
print(f"AUC Score: {auc_score:.2f}")

print("\n=== TOP 3 IMPORTANT FEATURES ===")
print(importance_df.nlargest(3, 'Importance')[['Feature', 'Importance']])
